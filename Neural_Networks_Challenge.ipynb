{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Neural Networks Challenge",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "uVGWbZAzodcA",
        "M9SIcHpDodcM",
        "FBgFAgmcodcU",
        "9ytjV3fLodce"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunomoraisnc/neural-networks-challenge/blob/master/Neural_Networks_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwSdqrUpoda-",
        "colab_type": "text"
      },
      "source": [
        "# DESAFIO\n",
        "## Bruno Morais Neves de Castro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhoIq1TpodbA",
        "colab_type": "text"
      },
      "source": [
        "# Sobre o dataset\n",
        "O dataset é composto por 130 amostras de indivíduos neurologicamente saudáveis e com Doença de Parkinson, sendo classificados como:\n",
        "- 0: indivíduos neurologicamente saudáveis\n",
        "- 1: indivíduos com Doença de Parkinson\n",
        "\n",
        "Para classificação, são utilizadas 408 características. As três com maior desvio-padrão serão separadas para treinamento e teste, bem como a coluna Class, que representa a classificação de cada amostra.\n",
        "\n",
        "Por fim, será calculada a precisão da arquitetura.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiBfP5LxodbB",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhgrGV_FodbB",
        "colab_type": "code",
        "outputId": "88501102-6f2d-4cac-ac88-58941ae02c18",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Divisor de treino-teste e Classificador\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Métricas\n",
        "from sklearn.cross_validation import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Gráfico\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\BM\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4qaKcsVodbH",
        "colab_type": "text"
      },
      "source": [
        "# Leitura de arquivo e análise primária"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "DArZ92R3odbH",
        "colab_type": "code",
        "outputId": "d5f35ccb-de29-4819-9491-d8caefcda65b",
        "colab": {}
      },
      "source": [
        "# DataFrame.read_csv() para leitura do arquivo CSV\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# DataFrame.head() pra visualização das primeiras 5 linhas\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample</th>\n",
              "      <th>Class</th>\n",
              "      <th>Feat1</th>\n",
              "      <th>Feat2</th>\n",
              "      <th>Feat3</th>\n",
              "      <th>Feat4</th>\n",
              "      <th>Feat5</th>\n",
              "      <th>Feat6</th>\n",
              "      <th>Feat7</th>\n",
              "      <th>Feat8</th>\n",
              "      <th>...</th>\n",
              "      <th>Feat399</th>\n",
              "      <th>Feat400</th>\n",
              "      <th>Feat401</th>\n",
              "      <th>Feat402</th>\n",
              "      <th>Feat403</th>\n",
              "      <th>Feat404</th>\n",
              "      <th>Feat405</th>\n",
              "      <th>Feat406</th>\n",
              "      <th>Feat407</th>\n",
              "      <th>Feat408</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.848430</td>\n",
              "      <td>0.976769</td>\n",
              "      <td>2.119157</td>\n",
              "      <td>0.401087</td>\n",
              "      <td>0.391817</td>\n",
              "      <td>0.209463</td>\n",
              "      <td>0.199892</td>\n",
              "      <td>1.711195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000180</td>\n",
              "      <td>0.521561</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>7663.368074</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.000256</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>1.731288e-09</td>\n",
              "      <td>0.840290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.890184</td>\n",
              "      <td>1.027493</td>\n",
              "      <td>2.448104</td>\n",
              "      <td>0.417791</td>\n",
              "      <td>0.429628</td>\n",
              "      <td>0.207055</td>\n",
              "      <td>0.218954</td>\n",
              "      <td>1.823011</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000357</td>\n",
              "      <td>0.593006</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>5828.760675</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>3.629933e-09</td>\n",
              "      <td>0.882876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.678620</td>\n",
              "      <td>0.813339</td>\n",
              "      <td>3.022167</td>\n",
              "      <td>0.447307</td>\n",
              "      <td>0.364194</td>\n",
              "      <td>0.283599</td>\n",
              "      <td>0.188001</td>\n",
              "      <td>1.319033</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000283</td>\n",
              "      <td>0.585712</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>6796.401968</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.000382</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>2.840904e-09</td>\n",
              "      <td>0.707318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0.732323</td>\n",
              "      <td>0.846803</td>\n",
              "      <td>2.151257</td>\n",
              "      <td>0.393228</td>\n",
              "      <td>0.333159</td>\n",
              "      <td>0.236892</td>\n",
              "      <td>0.170046</td>\n",
              "      <td>1.388155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000231</td>\n",
              "      <td>0.656882</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>7577.451642</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000059</td>\n",
              "      <td>0.000347</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>2.577860e-09</td>\n",
              "      <td>1.085987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.784659</td>\n",
              "      <td>0.892075</td>\n",
              "      <td>1.972922</td>\n",
              "      <td>0.370282</td>\n",
              "      <td>0.330593</td>\n",
              "      <td>0.211374</td>\n",
              "      <td>0.168490</td>\n",
              "      <td>1.627952</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000314</td>\n",
              "      <td>0.645609</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>5212.056293</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>0.000074</td>\n",
              "      <td>5.461302e-09</td>\n",
              "      <td>1.095683</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 410 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sample  Class     Feat1     Feat2     Feat3     Feat4     Feat5     Feat6  \\\n",
              "0       1      0  0.848430  0.976769  2.119157  0.401087  0.391817  0.209463   \n",
              "1       2      0  0.890184  1.027493  2.448104  0.417791  0.429628  0.207055   \n",
              "2       3      0  0.678620  0.813339  3.022167  0.447307  0.364194  0.283599   \n",
              "3       4      0  0.732323  0.846803  2.151257  0.393228  0.333159  0.236892   \n",
              "4       5      0  0.784659  0.892075  1.972922  0.370282  0.330593  0.211374   \n",
              "\n",
              "      Feat7     Feat8    ...      Feat399   Feat400   Feat401      Feat402  \\\n",
              "0  0.199892  1.711195    ...     0.000180  0.521561  0.000022  7663.368074   \n",
              "1  0.218954  1.823011    ...     0.000357  0.593006  0.000036  5828.760675   \n",
              "2  0.188001  1.319033    ...     0.000283  0.585712  0.000031  6796.401968   \n",
              "3  0.170046  1.388155    ...     0.000231  0.656882  0.000033  7577.451642   \n",
              "4  0.168490  1.627952    ...     0.000314  0.645609  0.000048  5212.056293   \n",
              "\n",
              "    Feat403   Feat404   Feat405   Feat406       Feat407   Feat408  \n",
              "0  0.000013  0.000052  0.000256  0.000042  1.731288e-09  0.840290  \n",
              "1  0.000021  0.000071  0.000459  0.000060  3.629933e-09  0.882876  \n",
              "2  0.000019  0.000054  0.000382  0.000053  2.840904e-09  0.707318  \n",
              "3  0.000020  0.000059  0.000347  0.000051  2.577860e-09  1.085987  \n",
              "4  0.000028  0.000083  0.000458  0.000074  5.461302e-09  1.095683  \n",
              "\n",
              "[5 rows x 410 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNoaEyvModbK",
        "colab_type": "code",
        "outputId": "d4640ae5-7d1c-4ec0-cc67-c8b63c06edf5",
        "colab": {}
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample</th>\n",
              "      <th>Class</th>\n",
              "      <th>Feat1</th>\n",
              "      <th>Feat2</th>\n",
              "      <th>Feat3</th>\n",
              "      <th>Feat4</th>\n",
              "      <th>Feat5</th>\n",
              "      <th>Feat6</th>\n",
              "      <th>Feat7</th>\n",
              "      <th>Feat8</th>\n",
              "      <th>...</th>\n",
              "      <th>Feat399</th>\n",
              "      <th>Feat400</th>\n",
              "      <th>Feat401</th>\n",
              "      <th>Feat402</th>\n",
              "      <th>Feat403</th>\n",
              "      <th>Feat404</th>\n",
              "      <th>Feat405</th>\n",
              "      <th>Feat406</th>\n",
              "      <th>Feat407</th>\n",
              "      <th>Feat408</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>126</td>\n",
              "      <td>0</td>\n",
              "      <td>0.569157</td>\n",
              "      <td>0.682674</td>\n",
              "      <td>2.063113</td>\n",
              "      <td>0.423187</td>\n",
              "      <td>0.289064</td>\n",
              "      <td>0.333461</td>\n",
              "      <td>0.155585</td>\n",
              "      <td>1.090291</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000429</td>\n",
              "      <td>0.326235</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>1373.053576</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000205</td>\n",
              "      <td>0.000733</td>\n",
              "      <td>0.000133</td>\n",
              "      <td>1.756993e-08</td>\n",
              "      <td>0.819280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>127</td>\n",
              "      <td>0</td>\n",
              "      <td>0.501284</td>\n",
              "      <td>0.613063</td>\n",
              "      <td>2.231598</td>\n",
              "      <td>0.493062</td>\n",
              "      <td>0.302094</td>\n",
              "      <td>0.445738</td>\n",
              "      <td>0.167325</td>\n",
              "      <td>0.923001</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>0.259205</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>1023.295014</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000239</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>0.000139</td>\n",
              "      <td>1.926374e-08</td>\n",
              "      <td>0.690093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0.642330</td>\n",
              "      <td>0.743330</td>\n",
              "      <td>2.391205</td>\n",
              "      <td>0.386707</td>\n",
              "      <td>0.287513</td>\n",
              "      <td>0.276608</td>\n",
              "      <td>0.152903</td>\n",
              "      <td>1.314005</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000611</td>\n",
              "      <td>0.340910</td>\n",
              "      <td>0.000042</td>\n",
              "      <td>1536.575225</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000171</td>\n",
              "      <td>0.000843</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>1.537096e-08</td>\n",
              "      <td>0.827274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>129</td>\n",
              "      <td>0</td>\n",
              "      <td>0.608932</td>\n",
              "      <td>0.710863</td>\n",
              "      <td>1.730564</td>\n",
              "      <td>0.369910</td>\n",
              "      <td>0.263210</td>\n",
              "      <td>0.283049</td>\n",
              "      <td>0.143309</td>\n",
              "      <td>1.223391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000550</td>\n",
              "      <td>0.235875</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>668.175357</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000315</td>\n",
              "      <td>0.000856</td>\n",
              "      <td>0.000195</td>\n",
              "      <td>3.800515e-08</td>\n",
              "      <td>0.636331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>130</td>\n",
              "      <td>0</td>\n",
              "      <td>0.509642</td>\n",
              "      <td>0.599982</td>\n",
              "      <td>1.592072</td>\n",
              "      <td>0.392971</td>\n",
              "      <td>0.235870</td>\n",
              "      <td>0.357336</td>\n",
              "      <td>0.128737</td>\n",
              "      <td>1.015288</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000405</td>\n",
              "      <td>0.298547</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>1347.289354</td>\n",
              "      <td>0.000021</td>\n",
              "      <td>0.000183</td>\n",
              "      <td>0.000640</td>\n",
              "      <td>0.000126</td>\n",
              "      <td>1.583946e-08</td>\n",
              "      <td>0.745375</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 410 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Sample  Class     Feat1     Feat2     Feat3     Feat4     Feat5  \\\n",
              "125     126      0  0.569157  0.682674  2.063113  0.423187  0.289064   \n",
              "126     127      0  0.501284  0.613063  2.231598  0.493062  0.302094   \n",
              "127     128      0  0.642330  0.743330  2.391205  0.386707  0.287513   \n",
              "128     129      0  0.608932  0.710863  1.730564  0.369910  0.263210   \n",
              "129     130      0  0.509642  0.599982  1.592072  0.392971  0.235870   \n",
              "\n",
              "        Feat6     Feat7     Feat8    ...      Feat399   Feat400   Feat401  \\\n",
              "125  0.333461  0.155585  1.090291    ...     0.000429  0.326235  0.000043   \n",
              "126  0.445738  0.167325  0.923001    ...     0.000340  0.259205  0.000036   \n",
              "127  0.276608  0.152903  1.314005    ...     0.000611  0.340910  0.000042   \n",
              "128  0.283049  0.143309  1.223391    ...     0.000550  0.235875  0.000046   \n",
              "129  0.357336  0.128737  1.015288    ...     0.000405  0.298547  0.000038   \n",
              "\n",
              "         Feat402   Feat403   Feat404   Feat405   Feat406       Feat407  \\\n",
              "125  1373.053576  0.000024  0.000205  0.000733  0.000133  1.756993e-08   \n",
              "126  1023.295014  0.000020  0.000239  0.000598  0.000139  1.926374e-08   \n",
              "127  1536.575225  0.000024  0.000171  0.000843  0.000124  1.537096e-08   \n",
              "128   668.175357  0.000025  0.000315  0.000856  0.000195  3.800515e-08   \n",
              "129  1347.289354  0.000021  0.000183  0.000640  0.000126  1.583946e-08   \n",
              "\n",
              "      Feat408  \n",
              "125  0.819280  \n",
              "126  0.690093  \n",
              "127  0.827274  \n",
              "128  0.636331  \n",
              "129  0.745375  \n",
              "\n",
              "[5 rows x 410 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "re0WzP4aodbN",
        "colab_type": "code",
        "outputId": "416946a1-0ec9-4e0f-ff78-6a2eb38d30d6",
        "colab": {}
      },
      "source": [
        "# Apresenta a forma do dataframe (linhas, colunas)\n",
        "print('-> O dataset apresenta %s linhas e %s colunas' % (df.shape[0], df.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-> O dataset apresenta 130 linhas e 410 colunas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQGPUhcqodbQ",
        "colab_type": "code",
        "outputId": "335b0a9b-a28f-4158-ef8e-8dcb10f2cead",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 130 entries, 0 to 129\n",
            "Columns: 410 entries, Sample to Feat408\n",
            "dtypes: float64(408), int64(2)\n",
            "memory usage: 416.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_Es1jePodbT",
        "colab_type": "code",
        "outputId": "59a1296c-b625-48ea-dd8c-4b73895e8c5c",
        "colab": {}
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample</th>\n",
              "      <th>Class</th>\n",
              "      <th>Feat1</th>\n",
              "      <th>Feat2</th>\n",
              "      <th>Feat3</th>\n",
              "      <th>Feat4</th>\n",
              "      <th>Feat5</th>\n",
              "      <th>Feat6</th>\n",
              "      <th>Feat7</th>\n",
              "      <th>Feat8</th>\n",
              "      <th>...</th>\n",
              "      <th>Feat399</th>\n",
              "      <th>Feat400</th>\n",
              "      <th>Feat401</th>\n",
              "      <th>Feat402</th>\n",
              "      <th>Feat403</th>\n",
              "      <th>Feat404</th>\n",
              "      <th>Feat405</th>\n",
              "      <th>Feat406</th>\n",
              "      <th>Feat407</th>\n",
              "      <th>Feat408</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>1.300000e+02</td>\n",
              "      <td>130.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>65.500000</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.592610</td>\n",
              "      <td>0.710024</td>\n",
              "      <td>2.149688</td>\n",
              "      <td>0.476573</td>\n",
              "      <td>0.335603</td>\n",
              "      <td>0.456709</td>\n",
              "      <td>0.181947</td>\n",
              "      <td>1.110362</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>0.674909</td>\n",
              "      <td>0.000087</td>\n",
              "      <td>3759.917748</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.000184</td>\n",
              "      <td>0.000835</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>3.038975e-08</td>\n",
              "      <td>0.962892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>37.671829</td>\n",
              "      <td>0.488386</td>\n",
              "      <td>0.245061</td>\n",
              "      <td>0.282331</td>\n",
              "      <td>0.842607</td>\n",
              "      <td>0.172285</td>\n",
              "      <td>0.161663</td>\n",
              "      <td>0.345127</td>\n",
              "      <td>0.087964</td>\n",
              "      <td>0.494658</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000481</td>\n",
              "      <td>0.279323</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>2268.586194</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000662</td>\n",
              "      <td>0.000101</td>\n",
              "      <td>8.076238e-08</td>\n",
              "      <td>0.237337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.119649</td>\n",
              "      <td>0.164174</td>\n",
              "      <td>0.536380</td>\n",
              "      <td>0.236233</td>\n",
              "      <td>0.063104</td>\n",
              "      <td>0.167250</td>\n",
              "      <td>0.033213</td>\n",
              "      <td>0.185097</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>0.136910</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>111.275258</td>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000230</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>8.718087e-10</td>\n",
              "      <td>0.267001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>33.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.415391</td>\n",
              "      <td>0.500463</td>\n",
              "      <td>1.469270</td>\n",
              "      <td>0.370003</td>\n",
              "      <td>0.221992</td>\n",
              "      <td>0.247132</td>\n",
              "      <td>0.118044</td>\n",
              "      <td>0.752947</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000317</td>\n",
              "      <td>0.422467</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>1842.965762</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>0.000128</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>9.646321e-09</td>\n",
              "      <td>0.807635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>65.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.609830</td>\n",
              "      <td>0.729982</td>\n",
              "      <td>2.134605</td>\n",
              "      <td>0.428900</td>\n",
              "      <td>0.329895</td>\n",
              "      <td>0.326057</td>\n",
              "      <td>0.178006</td>\n",
              "      <td>1.124824</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>0.704491</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>3676.042069</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>0.000168</td>\n",
              "      <td>0.000695</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>1.525041e-08</td>\n",
              "      <td>1.036417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>97.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.737808</td>\n",
              "      <td>0.882975</td>\n",
              "      <td>2.634550</td>\n",
              "      <td>0.505998</td>\n",
              "      <td>0.437823</td>\n",
              "      <td>0.532868</td>\n",
              "      <td>0.232032</td>\n",
              "      <td>1.387620</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000529</td>\n",
              "      <td>0.915883</td>\n",
              "      <td>0.000116</td>\n",
              "      <td>5266.909375</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.000233</td>\n",
              "      <td>0.000939</td>\n",
              "      <td>0.000165</td>\n",
              "      <td>2.707022e-08</td>\n",
              "      <td>1.148405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>130.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.361999</td>\n",
              "      <td>1.569427</td>\n",
              "      <td>5.111346</td>\n",
              "      <td>1.018624</td>\n",
              "      <td>0.841293</td>\n",
              "      <td>1.878176</td>\n",
              "      <td>0.436771</td>\n",
              "      <td>2.619333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005311</td>\n",
              "      <td>1.237924</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>10543.302620</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>0.000593</td>\n",
              "      <td>0.006908</td>\n",
              "      <td>0.000884</td>\n",
              "      <td>7.807907e-07</td>\n",
              "      <td>1.365530</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 410 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Sample       Class       Feat1       Feat2       Feat3       Feat4  \\\n",
              "count  130.000000  130.000000  130.000000  130.000000  130.000000  130.000000   \n",
              "mean    65.500000    0.615385    0.592610    0.710024    2.149688    0.476573   \n",
              "std     37.671829    0.488386    0.245061    0.282331    0.842607    0.172285   \n",
              "min      1.000000    0.000000    0.119649    0.164174    0.536380    0.236233   \n",
              "25%     33.250000    0.000000    0.415391    0.500463    1.469270    0.370003   \n",
              "50%     65.500000    1.000000    0.609830    0.729982    2.134605    0.428900   \n",
              "75%     97.750000    1.000000    0.737808    0.882975    2.634550    0.505998   \n",
              "max    130.000000    1.000000    1.361999    1.569427    5.111346    1.018624   \n",
              "\n",
              "            Feat5       Feat6       Feat7       Feat8     ...         Feat399  \\\n",
              "count  130.000000  130.000000  130.000000  130.000000     ...      130.000000   \n",
              "mean     0.335603    0.456709    0.181947    1.110362     ...        0.000485   \n",
              "std      0.161663    0.345127    0.087964    0.494658     ...        0.000481   \n",
              "min      0.063104    0.167250    0.033213    0.185097     ...        0.000144   \n",
              "25%      0.221992    0.247132    0.118044    0.752947     ...        0.000317   \n",
              "50%      0.329895    0.326057    0.178006    1.124824     ...        0.000389   \n",
              "75%      0.437823    0.532868    0.232032    1.387620     ...        0.000529   \n",
              "max      0.841293    1.878176    0.436771    2.619333     ...        0.005311   \n",
              "\n",
              "          Feat400     Feat401       Feat402     Feat403     Feat404  \\\n",
              "count  130.000000  130.000000    130.000000  130.000000  130.000000   \n",
              "mean     0.674909    0.000087   3759.917748    0.000051    0.000184   \n",
              "std      0.279323    0.000044   2268.586194    0.000026    0.000100   \n",
              "min      0.136910    0.000014    111.275258    0.000008    0.000011   \n",
              "25%      0.422467    0.000046   1842.965762    0.000025    0.000128   \n",
              "50%      0.704491    0.000089   3676.042069    0.000053    0.000168   \n",
              "75%      0.915883    0.000116   5266.909375    0.000068    0.000233   \n",
              "max      1.237924    0.000192  10543.302620    0.000110    0.000593   \n",
              "\n",
              "          Feat405     Feat406       Feat407     Feat408  \n",
              "count  130.000000  130.000000  1.300000e+02  130.000000  \n",
              "mean     0.000835    0.000142  3.038975e-08    0.962892  \n",
              "std      0.000662    0.000101  8.076238e-08    0.237337  \n",
              "min      0.000230    0.000030  8.718087e-10    0.267001  \n",
              "25%      0.000584    0.000098  9.646321e-09    0.807635  \n",
              "50%      0.000695    0.000123  1.525041e-08    1.036417  \n",
              "75%      0.000939    0.000165  2.707022e-08    1.148405  \n",
              "max      0.006908    0.000884  7.807907e-07    1.365530  \n",
              "\n",
              "[8 rows x 410 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X--JU6ThodbX",
        "colab_type": "code",
        "outputId": "732cc422-b93f-4d65-8602-a5709d6b5124",
        "colab": {}
      },
      "source": [
        "# Checar se há colunas com quantidade de amostra diferente de 130\n",
        "linhaCount = df.describe().loc['count', :]\n",
        "print(linhaCount[linhaCount != 130])\n",
        "print('-> Não há colunas com quantidade de amostra diferente de 130')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Series([], Name: count, dtype: float64)\n",
            "-> Não há colunas com quantidade de amostra diferente de 130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev3v8i-Aodba",
        "colab_type": "code",
        "outputId": "ad3ed483-bbad-4f77-ec2c-73bc8807d3b3",
        "colab": {}
      },
      "source": [
        "# Quantidade de indivíduos com o sem Doença de Parkinson\n",
        "classe = df.loc[:, 'Class'].values\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.hist(classe, bins=3)\n",
        "plt.xticks([0,1], ('Sem DP', 'Com DP'));\n",
        "\n",
        "plt.title('Quantidade DP vs Sem DP')\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Quantidade')\n",
        "\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5Jt4P0Codbd",
        "colab_type": "text"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxpCF0v7odbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para deletar a coluna sample:\n",
        "df.drop(axis=1, columns='Sample', inplace=True)\n",
        "\n",
        "# Observação:\n",
        "# após a primeira execução, pode apresentar erro, pois a coluna Sample é deletada inplace."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8bnHRSFodbg",
        "colab_type": "code",
        "outputId": "ada37589-1359-4808-d1c2-fdff47083032",
        "colab": {}
      },
      "source": [
        "# Deletar linha duplicada\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(130, 409)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiRCtgQ7odbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para coletar o desvio-padrão por coluna\n",
        "planilha = df.describe()\n",
        "\n",
        "# Separação dos índices de média (mean) e desvio-padrão (std)\n",
        "indices = ['mean', 'std']\n",
        "\n",
        "# Seleção de linhas atribuídas na variável indices e todas as colunas do dataframe, exceto Class\n",
        "planilhaMediaSTD = planilha.loc[indices, :]\n",
        "planilhaMediaSTD.drop(axis=1, columns='Class', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHzFZh4_odbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Para salvar em CSV:\n",
        "#\n",
        "# planilhaMediaSTD.to_csv('desvio_padrao_e_media.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr8-ovP4odbm",
        "colab_type": "code",
        "outputId": "8b35f094-b1c7-4a87-b21d-1ce7325aa806",
        "colab": {}
      },
      "source": [
        "# Para checar se há valores negativos\n",
        "print('Valor mínimo da linha min: {}'.format(min(planilha.loc['min',:])))\n",
        "\n",
        "if min(planilha.loc['min',:]) >= 0:\n",
        "    print('-> Não há valor negativo')\n",
        "else:\n",
        "    print('-> Há valor negativo')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valor mínimo da linha min: 0.0\n",
            "-> Não há valor negativo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "uyHHaV_Hodbq",
        "colab_type": "code",
        "outputId": "eb515e9f-2426-4ee3-b415-d302e2a5394d",
        "colab": {}
      },
      "source": [
        "# Para descobrir quais as colunas com maior desvio-padrão\n",
        "planilhaMediaSTD.sort_values(axis=1, by='std', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feat342</th>\n",
              "      <th>Feat402</th>\n",
              "      <th>Feat354</th>\n",
              "      <th>Feat294</th>\n",
              "      <th>Feat390</th>\n",
              "      <th>Feat366</th>\n",
              "      <th>Feat246</th>\n",
              "      <th>Feat306</th>\n",
              "      <th>Feat318</th>\n",
              "      <th>Feat378</th>\n",
              "      <th>...</th>\n",
              "      <th>Feat299</th>\n",
              "      <th>Feat335</th>\n",
              "      <th>Feat311</th>\n",
              "      <th>Feat323</th>\n",
              "      <th>Feat395</th>\n",
              "      <th>Feat383</th>\n",
              "      <th>Feat359</th>\n",
              "      <th>Feat371</th>\n",
              "      <th>Feat347</th>\n",
              "      <th>Feat407</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1223.825146</td>\n",
              "      <td>3759.917748</td>\n",
              "      <td>858.977468</td>\n",
              "      <td>783.661128</td>\n",
              "      <td>2208.712808</td>\n",
              "      <td>593.899584</td>\n",
              "      <td>855.595786</td>\n",
              "      <td>476.655168</td>\n",
              "      <td>352.901401</td>\n",
              "      <td>415.126172</td>\n",
              "      <td>...</td>\n",
              "      <td>2.733366e-07</td>\n",
              "      <td>3.178240e-07</td>\n",
              "      <td>2.142201e-07</td>\n",
              "      <td>3.032842e-07</td>\n",
              "      <td>7.477859e-08</td>\n",
              "      <td>2.027164e-07</td>\n",
              "      <td>1.290015e-07</td>\n",
              "      <td>1.306024e-07</td>\n",
              "      <td>1.116671e-07</td>\n",
              "      <td>3.038975e-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3464.299694</td>\n",
              "      <td>2268.586194</td>\n",
              "      <td>2138.170952</td>\n",
              "      <td>1373.010706</td>\n",
              "      <td>1333.804523</td>\n",
              "      <td>1193.475014</td>\n",
              "      <td>753.684160</td>\n",
              "      <td>700.882629</td>\n",
              "      <td>631.881333</td>\n",
              "      <td>571.035836</td>\n",
              "      <td>...</td>\n",
              "      <td>4.743192e-07</td>\n",
              "      <td>4.007942e-07</td>\n",
              "      <td>3.212362e-07</td>\n",
              "      <td>2.946497e-07</td>\n",
              "      <td>1.838228e-07</td>\n",
              "      <td>1.730343e-07</td>\n",
              "      <td>1.443134e-07</td>\n",
              "      <td>1.287825e-07</td>\n",
              "      <td>1.205603e-07</td>\n",
              "      <td>8.076238e-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 408 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Feat342      Feat402      Feat354      Feat294      Feat390  \\\n",
              "mean  1223.825146  3759.917748   858.977468   783.661128  2208.712808   \n",
              "std   3464.299694  2268.586194  2138.170952  1373.010706  1333.804523   \n",
              "\n",
              "          Feat366     Feat246     Feat306     Feat318     Feat378  \\\n",
              "mean   593.899584  855.595786  476.655168  352.901401  415.126172   \n",
              "std   1193.475014  753.684160  700.882629  631.881333  571.035836   \n",
              "\n",
              "          ...            Feat299       Feat335       Feat311       Feat323  \\\n",
              "mean      ...       2.733366e-07  3.178240e-07  2.142201e-07  3.032842e-07   \n",
              "std       ...       4.743192e-07  4.007942e-07  3.212362e-07  2.946497e-07   \n",
              "\n",
              "           Feat395       Feat383       Feat359       Feat371       Feat347  \\\n",
              "mean  7.477859e-08  2.027164e-07  1.290015e-07  1.306024e-07  1.116671e-07   \n",
              "std   1.838228e-07  1.730343e-07  1.443134e-07  1.287825e-07  1.205603e-07   \n",
              "\n",
              "           Feat407  \n",
              "mean  3.038975e-08  \n",
              "std   8.076238e-08  \n",
              "\n",
              "[2 rows x 408 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfk4VxDgodbu",
        "colab_type": "code",
        "outputId": "3657a2b9-9086-4a43-923a-3bcde618a3b2",
        "colab": {}
      },
      "source": [
        "# Para checar se a Feat342 é a maior mesmo\n",
        "planilhaMediaSTD.loc['std',:].max()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3464.299693954662"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo_eTqD2odbx",
        "colab_type": "code",
        "outputId": "749f2fea-3ede-44fc-ad34-037e3d5be60e",
        "colab": {}
      },
      "source": [
        "# Feat342, Feat402 e Feat354 têm os maiores stds\n",
        "caracterMaiorDP = ['Feat342', 'Feat402','Feat354']\n",
        "# dfFinal, com as amostras de características de maior desvio-padrão e coluna Class\n",
        "dfFinal = df.loc[:, caracterMaiorDP + ['Class']]\n",
        "dfFinal"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feat342</th>\n",
              "      <th>Feat402</th>\n",
              "      <th>Feat354</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>278.603665</td>\n",
              "      <td>7663.368074</td>\n",
              "      <td>273.043531</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>460.635378</td>\n",
              "      <td>5828.760675</td>\n",
              "      <td>344.151819</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>244.536630</td>\n",
              "      <td>6796.401968</td>\n",
              "      <td>236.495586</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>410.106465</td>\n",
              "      <td>7577.451642</td>\n",
              "      <td>301.223799</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358.100538</td>\n",
              "      <td>5212.056293</td>\n",
              "      <td>268.112779</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1205.262212</td>\n",
              "      <td>5113.544354</td>\n",
              "      <td>1463.103586</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>503.661400</td>\n",
              "      <td>7852.142007</td>\n",
              "      <td>711.997036</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>538.914202</td>\n",
              "      <td>6877.352030</td>\n",
              "      <td>1962.727798</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1002.043556</td>\n",
              "      <td>7524.091627</td>\n",
              "      <td>1301.954902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>856.115456</td>\n",
              "      <td>7479.312365</td>\n",
              "      <td>1628.868332</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>429.715911</td>\n",
              "      <td>5962.599811</td>\n",
              "      <td>772.268534</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>451.892853</td>\n",
              "      <td>7669.313612</td>\n",
              "      <td>1979.959459</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>861.323315</td>\n",
              "      <td>8885.439677</td>\n",
              "      <td>1059.023417</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1219.476662</td>\n",
              "      <td>6539.965549</td>\n",
              "      <td>1484.752734</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>436.380760</td>\n",
              "      <td>10543.302620</td>\n",
              "      <td>832.784276</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>239.050155</td>\n",
              "      <td>322.718038</td>\n",
              "      <td>193.959896</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>249.314621</td>\n",
              "      <td>518.230773</td>\n",
              "      <td>154.738192</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>228.794342</td>\n",
              "      <td>620.735733</td>\n",
              "      <td>161.618671</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>236.833117</td>\n",
              "      <td>774.375366</td>\n",
              "      <td>142.499056</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>218.392031</td>\n",
              "      <td>1152.263157</td>\n",
              "      <td>184.462444</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>187.296474</td>\n",
              "      <td>1578.797377</td>\n",
              "      <td>730.647803</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>151.160168</td>\n",
              "      <td>2137.642459</td>\n",
              "      <td>870.949048</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>204.642561</td>\n",
              "      <td>1817.514935</td>\n",
              "      <td>798.699845</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>252.786818</td>\n",
              "      <td>2636.221697</td>\n",
              "      <td>812.740170</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>222.266602</td>\n",
              "      <td>1086.624360</td>\n",
              "      <td>643.523329</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>193.231996</td>\n",
              "      <td>768.287793</td>\n",
              "      <td>420.825256</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>157.240280</td>\n",
              "      <td>1384.010494</td>\n",
              "      <td>354.187490</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>158.897309</td>\n",
              "      <td>2720.104446</td>\n",
              "      <td>502.366283</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>153.122566</td>\n",
              "      <td>2261.901324</td>\n",
              "      <td>505.306281</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>189.881775</td>\n",
              "      <td>1266.730917</td>\n",
              "      <td>687.043812</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>92.067201</td>\n",
              "      <td>5285.193736</td>\n",
              "      <td>89.983388</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>70.979063</td>\n",
              "      <td>6244.308744</td>\n",
              "      <td>116.207519</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>104.841791</td>\n",
              "      <td>7274.739732</td>\n",
              "      <td>157.411627</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>83.537775</td>\n",
              "      <td>7432.232478</td>\n",
              "      <td>97.980013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>92.331245</td>\n",
              "      <td>5471.678231</td>\n",
              "      <td>80.562935</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>392.805746</td>\n",
              "      <td>1941.343553</td>\n",
              "      <td>2571.918803</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>342.632982</td>\n",
              "      <td>1919.318243</td>\n",
              "      <td>2138.053798</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>539.389270</td>\n",
              "      <td>1702.656438</td>\n",
              "      <td>2748.854222</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>662.877648</td>\n",
              "      <td>2464.335343</td>\n",
              "      <td>3618.317668</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>931.494205</td>\n",
              "      <td>3666.500588</td>\n",
              "      <td>6597.239238</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>135.492412</td>\n",
              "      <td>2110.562087</td>\n",
              "      <td>252.701513</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>145.607711</td>\n",
              "      <td>3526.223924</td>\n",
              "      <td>213.713174</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>140.743249</td>\n",
              "      <td>2867.013478</td>\n",
              "      <td>242.412714</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>130.795536</td>\n",
              "      <td>3015.613850</td>\n",
              "      <td>260.780683</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>319.148908</td>\n",
              "      <td>3371.434117</td>\n",
              "      <td>346.660602</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>98.895309</td>\n",
              "      <td>1338.362240</td>\n",
              "      <td>252.731190</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>82.243175</td>\n",
              "      <td>3968.020493</td>\n",
              "      <td>250.872767</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>131.823675</td>\n",
              "      <td>4165.594321</td>\n",
              "      <td>358.018725</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>108.216072</td>\n",
              "      <td>3427.741817</td>\n",
              "      <td>280.386696</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>154.290733</td>\n",
              "      <td>4708.199458</td>\n",
              "      <td>194.451315</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>523.139652</td>\n",
              "      <td>2761.938730</td>\n",
              "      <td>210.122329</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>467.827673</td>\n",
              "      <td>3790.529824</td>\n",
              "      <td>469.806635</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>872.642152</td>\n",
              "      <td>3501.663442</td>\n",
              "      <td>507.341626</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>735.365476</td>\n",
              "      <td>3842.895537</td>\n",
              "      <td>530.028044</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>537.363677</td>\n",
              "      <td>4272.875186</td>\n",
              "      <td>408.387089</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>1354.527020</td>\n",
              "      <td>1373.053576</td>\n",
              "      <td>593.968837</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>1416.712295</td>\n",
              "      <td>1023.295014</td>\n",
              "      <td>790.646254</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>2112.671892</td>\n",
              "      <td>1536.575225</td>\n",
              "      <td>721.346125</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>4373.866511</td>\n",
              "      <td>668.175357</td>\n",
              "      <td>668.840472</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>2454.072672</td>\n",
              "      <td>1347.289354</td>\n",
              "      <td>541.602938</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Feat342       Feat402      Feat354  Class\n",
              "0     278.603665   7663.368074   273.043531      0\n",
              "1     460.635378   5828.760675   344.151819      0\n",
              "2     244.536630   6796.401968   236.495586      0\n",
              "3     410.106465   7577.451642   301.223799      0\n",
              "4     358.100538   5212.056293   268.112779      0\n",
              "5    1205.262212   5113.544354  1463.103586      0\n",
              "6     503.661400   7852.142007   711.997036      0\n",
              "7     538.914202   6877.352030  1962.727798      0\n",
              "8    1002.043556   7524.091627  1301.954902      0\n",
              "9     856.115456   7479.312365  1628.868332      0\n",
              "10    429.715911   5962.599811   772.268534      0\n",
              "11    451.892853   7669.313612  1979.959459      0\n",
              "12    861.323315   8885.439677  1059.023417      0\n",
              "13   1219.476662   6539.965549  1484.752734      0\n",
              "14    436.380760  10543.302620   832.784276      0\n",
              "15    239.050155    322.718038   193.959896      0\n",
              "16    249.314621    518.230773   154.738192      0\n",
              "17    228.794342    620.735733   161.618671      0\n",
              "18    236.833117    774.375366   142.499056      0\n",
              "19    218.392031   1152.263157   184.462444      0\n",
              "20    187.296474   1578.797377   730.647803      0\n",
              "21    151.160168   2137.642459   870.949048      0\n",
              "22    204.642561   1817.514935   798.699845      0\n",
              "23    252.786818   2636.221697   812.740170      0\n",
              "24    222.266602   1086.624360   643.523329      0\n",
              "25    193.231996    768.287793   420.825256      0\n",
              "26    157.240280   1384.010494   354.187490      0\n",
              "27    158.897309   2720.104446   502.366283      0\n",
              "28    153.122566   2261.901324   505.306281      0\n",
              "29    189.881775   1266.730917   687.043812      0\n",
              "..           ...           ...          ...    ...\n",
              "100    92.067201   5285.193736    89.983388      1\n",
              "101    70.979063   6244.308744   116.207519      1\n",
              "102   104.841791   7274.739732   157.411627      1\n",
              "103    83.537775   7432.232478    97.980013      1\n",
              "104    92.331245   5471.678231    80.562935      1\n",
              "105   392.805746   1941.343553  2571.918803      1\n",
              "106   342.632982   1919.318243  2138.053798      1\n",
              "107   539.389270   1702.656438  2748.854222      1\n",
              "108   662.877648   2464.335343  3618.317668      1\n",
              "109   931.494205   3666.500588  6597.239238      1\n",
              "110   135.492412   2110.562087   252.701513      1\n",
              "111   145.607711   3526.223924   213.713174      1\n",
              "112   140.743249   2867.013478   242.412714      1\n",
              "113   130.795536   3015.613850   260.780683      1\n",
              "114   319.148908   3371.434117   346.660602      1\n",
              "115    98.895309   1338.362240   252.731190      1\n",
              "116    82.243175   3968.020493   250.872767      1\n",
              "117   131.823675   4165.594321   358.018725      1\n",
              "118   108.216072   3427.741817   280.386696      1\n",
              "119   154.290733   4708.199458   194.451315      1\n",
              "120   523.139652   2761.938730   210.122329      1\n",
              "121   467.827673   3790.529824   469.806635      1\n",
              "122   872.642152   3501.663442   507.341626      1\n",
              "123   735.365476   3842.895537   530.028044      1\n",
              "124   537.363677   4272.875186   408.387089      1\n",
              "125  1354.527020   1373.053576   593.968837      0\n",
              "126  1416.712295   1023.295014   790.646254      0\n",
              "127  2112.671892   1536.575225   721.346125      0\n",
              "128  4373.866511    668.175357   668.840472      0\n",
              "129  2454.072672   1347.289354   541.602938      0\n",
              "\n",
              "[130 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5yTNUTFodb0",
        "colab_type": "text"
      },
      "source": [
        "# Separação de X e y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wef_ySbGodb0",
        "colab_type": "code",
        "outputId": "8c2702cf-35e5-4c6b-f6bb-90059e9abf13",
        "colab": {}
      },
      "source": [
        "X = dfFinal.iloc[:, 0:3]\n",
        "X.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feat342</th>\n",
              "      <th>Feat402</th>\n",
              "      <th>Feat354</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>278.603665</td>\n",
              "      <td>7663.368074</td>\n",
              "      <td>273.043531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>460.635378</td>\n",
              "      <td>5828.760675</td>\n",
              "      <td>344.151819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>244.536630</td>\n",
              "      <td>6796.401968</td>\n",
              "      <td>236.495586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>410.106465</td>\n",
              "      <td>7577.451642</td>\n",
              "      <td>301.223799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358.100538</td>\n",
              "      <td>5212.056293</td>\n",
              "      <td>268.112779</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Feat342      Feat402     Feat354\n",
              "0  278.603665  7663.368074  273.043531\n",
              "1  460.635378  5828.760675  344.151819\n",
              "2  244.536630  6796.401968  236.495586\n",
              "3  410.106465  7577.451642  301.223799\n",
              "4  358.100538  5212.056293  268.112779"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tg3D8fsLodb5",
        "colab_type": "code",
        "outputId": "6f321d57-fb95-4bf8-ee91-37c03617676b",
        "colab": {}
      },
      "source": [
        "# .values para transformar para numpy array, que acelera os cálculos\n",
        "y = dfFinal.loc[:,'Class'].values\n",
        "\n",
        "print('Tipo de dado de y: %s \\n' % type(y))\n",
        "print('Valores de y:')\n",
        "print(y)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tipo de dado de y: <class 'numpy.ndarray'> \n",
            "\n",
            "Valores de y:\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kwgRn6Lodb8",
        "colab_type": "text"
      },
      "source": [
        "# Normalização"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yymV-YIXodb9",
        "colab_type": "text"
      },
      "source": [
        "## Fórmula de normalização:\n",
        "X = (X - X.min())/(X.max() - X.min())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEREeQ_7odb9",
        "colab_type": "code",
        "outputId": "a03033e6-5bf0-44a5-af1a-deccd211dc37",
        "colab": {}
      },
      "source": [
        "print('Executando normalização...')\n",
        "\n",
        "X = (X - X.min(axis=0))/(X.max(axis=0) - X.min(axis=0))\n",
        "X.head()\n",
        "\n",
        "print('Normalização finalizada!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executando normalização...\n",
            "Normalização finalizada!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVGWbZAzodcA",
        "colab_type": "text"
      },
      "source": [
        "### Checagem de MÍNIMO e MÁXIMO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Idz8afodcB",
        "colab_type": "code",
        "outputId": "a47d1bce-7b0e-4db4-dacd-fff81e5330e0",
        "colab": {}
      },
      "source": [
        "print('Mínimo:')\n",
        "print(X.min())\n",
        "\n",
        "print('Máximo:')\n",
        "print(X.max())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mínimo:\n",
            "Feat342    0.0\n",
            "Feat402    0.0\n",
            "Feat354    0.0\n",
            "dtype: float64\n",
            "Máximo:\n",
            "Feat342    1.0\n",
            "Feat402    1.0\n",
            "Feat354    1.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tCtnvkKodcD",
        "colab_type": "text"
      },
      "source": [
        "# Separação Treino e Teste\n",
        "- Treino: 70%\n",
        "- Teste: 30%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEzRUU1dodcE",
        "colab_type": "code",
        "outputId": "ff87d96d-6aaa-47ac-aeb0-c9b909c95423",
        "colab": {}
      },
      "source": [
        "print('Separando valores de treino e teste...')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
        "\n",
        "print('Treino e teste foram separados em:')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Separando valores de treino e teste...\n",
            "Treino e teste foram separados em:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hhVAsA4BodcH",
        "colab_type": "code",
        "outputId": "713cf7b0-2a00-4e51-f3af-40c4a5ac3ce6",
        "colab": {}
      },
      "source": [
        "# Checando a forma de cada elemento (linha, colunas)\n",
        "\n",
        "print('Treino:')\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print('\\nTeste:')\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Treino:\n",
            "(91, 3)\n",
            "(91,)\n",
            "\n",
            "Teste:\n",
            "(39, 3)\n",
            "(39,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrY-Jw5VodcK",
        "colab_type": "text"
      },
      "source": [
        "# Função para testar várias arquiteturas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICj7o9HnodcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testarClassificadorMLP(ativador, otimizador, epocas=2000, momentumm=0.9, taxaAprendizagem='constant'):\n",
        "    '''\n",
        "    FUNÇÃO testarClassificadorMLP\n",
        "    \n",
        "    DESCRIÇÃO:\n",
        "    Função para testar precisão (em Erro Quadrático Médio - EQM) com diversas quantidades de tuplas em uma camada intermediária.\n",
        "    É possível, também, determinar arquiteturas e outros parâmetros do classificador sklearn.neural_network.MLPClassifier da biblioteca Scikit-learn.\n",
        "    \n",
        "    ENTRADAS:\n",
        "    - ativador:  {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}\n",
        "        define a função de ativação a ser percorrida.\n",
        "\n",
        "    - otimizador: {‘lbfgs’, ‘sgd’, ‘adam’'}\n",
        "        define o otimizador que será utilizado\n",
        "\n",
        "    - épocas: (DEFAULT=2000)\n",
        "        Para otimizadores 'sgd' e 'adam', define o número de épocas\n",
        "        Para outros, define o número de iterações\n",
        "\n",
        "    - momentum: [float de 0 a 1] (DEFAULT=0.9)\n",
        "        define a taxa de momentum.\n",
        "\n",
        "    - taxaDeAprendizagem: [float de 0 a 1] (DEFAULT='constant')\n",
        "        define a taxa de aprendizagem.\n",
        "    \n",
        "    SAÍDAS (void):\n",
        "    Apresenta a performance de cada formato de tupla.\n",
        "    \n",
        "    PARA MAIORES INFORMAÇÕES:\n",
        "    http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "    \n",
        "    AUTOR: BRUNO MORAIS NEVES DE CASTRO\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    listaEQMTeste = []\n",
        "    listaEQMTreino = []\n",
        "\n",
        "    for i in range(1,25):\n",
        "        clf = MLPClassifier(activation=ativador, solver=otimizador, hidden_layer_sizes=(i, ), random_state=21, max_iter=epocas, momentum=momentumm, learning_rate=taxaAprendizagem)\n",
        "        #print('\\n{} tupla(s) na camada\\n'.format(i))\n",
        "\n",
        "        #mediaCrossValidation = np.mean(cross_val_score(clf, X, y, cv=5))\n",
        "\n",
        "        #print('Média Cross-validation: {}'.format(mediaCrossValidation))\n",
        "\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        y_pred_train = clf.predict(X_train)\n",
        "        y_pred_test = clf.predict(X_test)\n",
        "\n",
        "        EQM_treino = mean_squared_error(y_train, y_pred_train)\n",
        "        EQM_teste = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "        score = clf.score(X_test,y_test)\n",
        "\n",
        "        #print('Score de Teste: {}'.format(score))\n",
        "        #print('EQM de Treino: {}'.format(EQM_treino))\n",
        "        #print('EQM de Teste: {}'.format(EQM_teste))\n",
        "\n",
        "        listaEQMTeste.append(EQM_teste)\n",
        "        listaEQMTreino.append(EQM_treino)\n",
        "\n",
        "    minListaEQMTeste = np.min(np.array(listaEQMTeste))\n",
        "    minListaEQMTreino = np.min(np.array(listaEQMTreino))\n",
        "    print('\\n######################################################')\n",
        "    print('Ativador [{}] e otimizador [{}]'.format(ativador, otimizador))\n",
        "    print('Mínimo EQM Teste: {}'.format(minListaEQMTeste))\n",
        "    print('Mínimo EQM Treino: {}'.format(minListaEQMTreino))\n",
        "    print('######################################################')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPcdS6yoodcM",
        "colab_type": "text"
      },
      "source": [
        "# Cálculo de Erro Quadrático Médio para diversas arquiteturas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9SIcHpDodcM",
        "colab_type": "text"
      },
      "source": [
        "### Sigmoidal (Logistic)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR5lLe6LodcN",
        "colab_type": "code",
        "outputId": "89bff192-53cf-41a9-e5ab-59e2b9d2bf51",
        "colab": {}
      },
      "source": [
        "testarClassificadorMLP(ativador='logistic', otimizador='lbfgs')\n",
        "# 5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################\n",
            "Ativador [logistic] e otimizador [lbfgs]\n",
            "Mínimo EQM Teste: 0.07692307692307693\n",
            "Mínimo EQM Treino: 0.0\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SEQsD9CodcP",
        "colab_type": "code",
        "outputId": "7ee3a2b6-afc5-42fe-fa9f-e3554eedeffd",
        "colab": {}
      },
      "source": [
        "testarClassificadorMLP(ativador='logistic', otimizador='sgd')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################\n",
            "Ativador [logistic] e otimizador [sgd]\n",
            "Mínimo EQM Teste: 0.38461538461538464\n",
            "Mínimo EQM Treino: 0.38461538461538464\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ljPZtnHxodcS",
        "colab_type": "code",
        "outputId": "a7d743cd-88b5-41a9-cc31-650d0a526389",
        "colab": {}
      },
      "source": [
        "testarClassificadorMLP(ativador='logistic', otimizador='adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################\n",
            "Ativador [logistic] e otimizador [adam]\n",
            "Mínimo EQM Teste: 0.38461538461538464\n",
            "Mínimo EQM Treino: 0.38461538461538464\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBgFAgmcodcU",
        "colab_type": "text"
      },
      "source": [
        "### Rectified (ReLU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "VY8_g65VodcV",
        "colab_type": "code",
        "outputId": "c8c8eedb-6e10-456e-8d98-80f8276fc63e",
        "colab": {}
      },
      "source": [
        "testarClassificadorMLP(ativador='relu', otimizador='lbfgs')\n",
        "# 11, 14, 17, 19"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################\n",
            "Ativador [relu] e otimizador [lbfgs]\n",
            "Mínimo EQM Teste: 0.10256410256410256\n",
            "Mínimo EQM Treino: 0.04395604395604396\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkJNmzmYodcX",
        "colab_type": "code",
        "outputId": "3ce4cf16-0baa-4ad5-8737-886975e59f50",
        "colab": {}
      },
      "source": [
        "testarClassificadorMLP(ativador='relu', otimizador='sgd')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################\n",
            "Ativador [relu] e otimizador [sgd]\n",
            "Mínimo EQM Teste: 0.38461538461538464\n",
            "Mínimo EQM Treino: 0.37362637362637363\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEBCv9TGodca",
        "colab_type": "code",
        "outputId": "edcb9bcd-1f60-4303-e1ce-df7b7234c89c",
        "colab": {}
      },
      "source": [
        "testarClassificadorMLP(ativador='relu', otimizador='adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################\n",
            "Ativador [relu] e otimizador [adam]\n",
            "Mínimo EQM Teste: 0.15384615384615385\n",
            "Mínimo EQM Treino: 0.13186813186813187\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ytjV3fLodce",
        "colab_type": "text"
      },
      "source": [
        "### Tangente Hiperbólica (tanh)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIGTQaL8odcf",
        "colab_type": "code",
        "outputId": "7b787fe9-9d48-4a49-9bba-c2e9b5473f62",
        "colab": {}
      },
      "source": [
        "testarClassificadorMLP(ativador='tanh', otimizador='lbfgs')\n",
        "# 6, 13"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################\n",
            "Ativador [tanh] e otimizador [lbfgs]\n",
            "Mínimo EQM Teste: 0.1282051282051282\n",
            "Mínimo EQM Treino: 0.0\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vi2mkWaodch",
        "colab_type": "code",
        "outputId": "9c9ed6bf-ddd5-4891-956c-93d39d3f7844",
        "colab": {}
      },
      "source": [
        "testarClassificadorMLP(ativador='tanh', otimizador='sgd')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################\n",
            "Ativador [tanh] e otimizador [sgd]\n",
            "Mínimo EQM Teste: 0.2564102564102564\n",
            "Mínimo EQM Treino: 0.2857142857142857\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcCMgjYXodcj",
        "colab_type": "code",
        "outputId": "f6aedc47-6f83-43e6-dd07-b6bf96a910df",
        "colab": {}
      },
      "source": [
        "testarClassificadorMLP(ativador='tanh', otimizador='adam')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################\n",
            "Ativador [tanh] e otimizador [adam]\n",
            "Mínimo EQM Teste: 0.1794871794871795\n",
            "Mínimo EQM Treino: 0.27472527472527475\n",
            "######################################################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG3wWhMjodcl",
        "colab_type": "text"
      },
      "source": [
        "# CÁLCULO DE PRECISÃO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QeEvZBhodcl",
        "colab_type": "text"
      },
      "source": [
        "## Arquiteturas com melhores scores:\n",
        "- Ativador [tanh] e otimizador [lbfgs]\n",
        "- Ativador [relu] e otimizador [lbfgs]\n",
        "- Ativador [logistic] e otimizador [lbfgs]\n",
        "\n",
        "Os demais argumentos estão na função testarClassificadorMLP() criada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qiuNaxZodcm",
        "colab_type": "code",
        "outputId": "c38f7c66-ba7e-46d3-f9fc-bb779ff548d2",
        "colab": {}
      },
      "source": [
        "clfTanhLBFGS = MLPClassifier(activation='tanh', solver='lbfgs', hidden_layer_sizes=(6, ), random_state=21, max_iter=2000)\n",
        "clfTanhLBFGS.fit(X_train, y_train)\n",
        "precisao = clfTanhLBFGS.score(X_test, y_test)\n",
        "\n",
        "print('\\nAtivador [tanh] e otimizador [lbfgs]')\n",
        "print('Precisão: {} %'.format(precisao * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Ativador [tanh] e otimizador [lbfgs]\n",
            "Precisão: 87.17948717948718 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "c8coDW6nodcq",
        "colab_type": "code",
        "outputId": "f9da91d6-08e4-4f94-a90f-30a62b72535a",
        "colab": {}
      },
      "source": [
        "clfReluLBFGS = MLPClassifier(activation='relu', solver='lbfgs', hidden_layer_sizes=(11, ), random_state=21, max_iter=2000)\n",
        "clfReluLBFGS.fit(X_train, y_train)\n",
        "precisao = clfReluLBFGS.score(X_test, y_test)\n",
        "\n",
        "print('\\nAtivador [relu] e otimizador [lbfgs]')\n",
        "print('Precisão: {} %'.format(precisao * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Ativador [relu] e otimizador [lbfgs]\n",
            "Precisão: 89.74358974358975 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "Dlz98pGbodcu",
        "colab_type": "code",
        "outputId": "67defc8f-fc24-4d2f-b8b4-9d118d337e87",
        "colab": {}
      },
      "source": [
        "clfLogisticLBFGS = MLPClassifier(activation='logistic', solver='lbfgs', hidden_layer_sizes=(5, ), random_state=21, max_iter=2000)\n",
        "clfLogisticLBFGS.fit(X_train, y_train)\n",
        "precisao = clfLogisticLBFGS.score(X_test, y_test)\n",
        "\n",
        "print('\\nAtivador [logistic] e otimizador [lbfgs]')\n",
        "print('Precisão: {} %'.format(precisao * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Ativador [logistic] e otimizador [lbfgs]\n",
            "Precisão: 92.3076923076923 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiQ-rpeCodcz",
        "colab_type": "text"
      },
      "source": [
        "# Gráfico de Precisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbrhkyPfodcz",
        "colab_type": "code",
        "outputId": "27a8b586-087a-4a7b-e343-68a52d08531e",
        "colab": {}
      },
      "source": [
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate a simple plot of the test and training learning curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 3-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - An object to be used as a cross-validation generator.\n",
        "          - An iterable yielding train/test splits.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : integer, optional\n",
        "        Number of jobs to run in parallel (default 1).\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "    plt.grid(True)\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "title = \"Curva de Aprendizado\"\n",
        "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=21)\n",
        "plot_learning_curve(clfLogisticLBFGS, title, X, y, cv=cv, n_jobs=4)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vcngy97lodc1",
        "colab_type": "text"
      },
      "source": [
        "# Relato\n",
        "\n",
        "A pesquisa, além de oportunizar o aprendizado, proporcionou imensa satisfação. Para a fase de limpeza de dados e divisão de características (X) e classe (y), o domínio da biblioteca pandas acelerou bastante o processo. Após a separação treino-teste e a normalização dos dados, procurei, então, não me ater somente aos passos mínimos, e resolvi extrapolar à procura das melhores arquiteturas que o classificador Multi-layer Perceptron (MLP) da biblioteca Scikit-learn poderia proporcionar, o que resultou na composição da função testarClassificadorMLP() para cálculo do Erro Quadrático Mínimo e Cross-validation de cada uma. Com isso, foi possível descobrir com qual quantidade de neurônios cada uma retornaria o melhor score com os 30% reservados para teste.\n",
        "\n",
        "O otimizador lbfgs, definido na documentação como sendo da família de métodos quasi-Newton, apresentou bons resultados com todas as funções de ativação. Aparentemente, ele retorna melhores resultados em datasets pequenos.\n",
        "\n",
        "O algoritmo utilizado para plotagem do gráfico foi o único de fonte externa, retirado da própria documentação do scikit-learn. Ainda assim, pequenas adaptações foram feitas.\n",
        "\n",
        "Por fim, estou ciente da necessidade de conceitos estatísticos e mais métricas para validação, e me empenharei para aprender tudo isso.\n",
        "\n",
        "Atenciosamente,\n",
        "\n",
        "Bruno Morais Neves de Castro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTO5rZ40odc2",
        "colab_type": "text"
      },
      "source": [
        "# ~FIM"
      ]
    }
  ]
}